{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "#import spacy\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3974, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Er is een teek op mijn been. Ik ben bang dat d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Er is een teek op mijn rug en ik krijg hem er ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Op mijn been zit een teek. Ik heb hem geprobee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ik heb allergieen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>huid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roodheid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>schilfering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ik heb wratten onder mijn voet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ik heb gisteren naar het bos geweest en zie nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ik voelde iets prikken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Er is een teek op mijn been. Ik ben bang dat d...\n",
       "1  Er is een teek op mijn rug en ik krijg hem er ...\n",
       "2  Op mijn been zit een teek. Ik heb hem geprobee...\n",
       "3                                  Ik heb allergieen\n",
       "4                                               huid\n",
       "5                                           roodheid\n",
       "6                                        schilfering\n",
       "7                     Ik heb wratten onder mijn voet\n",
       "8  Ik heb gisteren naar het bos geweest en zie nu...\n",
       "9                             Ik voelde iets prikken"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "df_user_inputs = pd.read_csv('../dataset/user_inputs.csv', delimiter=';')\n",
    "df_labels = pd.read_csv('../dataset/labels.csv', delimiter=\";\")\n",
    "\n",
    "# Remove unnecessary index columns\n",
    "df_user_inputs.drop(df_user_inputs.columns[0], axis=1, inplace=True)\n",
    "df_labels.drop(df_labels.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Remove classes with < 2 instances (this is only 'no complaints' label with 0 instance so not a big deal)\n",
    "# We need to do this to split the data later with stratification\n",
    "df_labels = df_labels.loc[:, (df_labels.sum(axis=0) >= 2)]\n",
    "\n",
    "# Ensure alignment\n",
    "assert len(df_labels) == len(df_user_inputs), \"Datasets do not align!\"\n",
    "\n",
    "print(df_user_inputs.shape)\n",
    "df_user_inputs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocess Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>er is een teek op mijn been ik ben bang dat di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>er is een teek op mijn rug en ik krijg hem er ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>op mijn been zit een teek ik heb hem geprobeer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ik heb allergieen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>huid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roodheid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>schilfering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ik heb wratten onder mijn voet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ik heb gisteren naar het bos geweest en zie nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ik voelde iets prikken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  er is een teek op mijn been ik ben bang dat di...\n",
       "1  er is een teek op mijn rug en ik krijg hem er ...\n",
       "2  op mijn been zit een teek ik heb hem geprobeer...\n",
       "3                                  ik heb allergieen\n",
       "4                                               huid\n",
       "5                                           roodheid\n",
       "6                                        schilfering\n",
       "7                     ik heb wratten onder mijn voet\n",
       "8  ik heb gisteren naar het bos geweest en zie nu...\n",
       "9                             ik voelde iets prikken"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preprocess user input text\n",
    "\n",
    "# Load the Dutch language model from Spacy\n",
    "#nlp = spacy.load(\"nl_core_news_sm\")\n",
    "\n",
    "# Set of Dutch stopwords from NLTK\n",
    "#dutch_stopwords = set(stopwords.words('dutch'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text by lowercasing, removing special characters, and removing stopwords.\n",
    "    Args:\n",
    "        text (str): The text to preprocess.\n",
    "    Returns:\n",
    "        str: The preprocessed text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    \"\"\"\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    filtered_tokens = [token for token in tokens if token not in dutch_stopwords]\n",
    "\n",
    "    # Lemmatize each token\n",
    "    doc = nlp(\" \".join(filtered_tokens))\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "    text = ' '.join(lemmas)\n",
    "    \"\"\"\n",
    "    return text\n",
    "\n",
    "df_user_inputs['text'] = df_user_inputs['text'].apply(preprocess_text)\n",
    "\n",
    "df_user_inputs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train-Test Split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accomodate the nature of multi-label classification. Instead of using the traditional method `train_test_split`, we employ iterative stratified sampling `iterative_train_test_split`, to provide a well-balanced distribution of all label combinations in both training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2773,) (2773, 74) (604,) (597,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['er is een teek op mijn been ik ben bang dat die er al een tijdje op heeft gezeten',\n",
       "       'roodheid', 'schilfering', ...,\n",
       "       'vannacht met slapen denk ik gekke beweging gemaakt want mn nek is nu helemaal stijf kan niet meer naar rechts kijken',\n",
       "       'heb al langere tijd pijn in mn nek krijg dan soms tintelingen over mijn arm heb dan ook minder kracht in mijn arm',\n",
       "       'doet zeer als ik mn hoofd beweeg'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split data to train:val:test\n",
    "\n",
    "# Prepare data for iterative train test split\n",
    "# X must be 2D np.ndarray and y must be 2D binary np.ndarray\n",
    "X_texts = df_user_inputs['text'].values\n",
    "X_texts = X_texts.reshape(-1, 1)\n",
    "y = df_labels.values\n",
    "\n",
    "# Split the data 70:15:15 with multi-label stratification\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "train_texts, y_train, tmp_texts, y_tmp = iterative_train_test_split(X_texts, y, test_size = 0.3)\n",
    "val_texts, y_val, test_texts, y_test = iterative_train_test_split(tmp_texts, y_tmp, test_size = 0.5)\n",
    "\n",
    "# Sanity checks to confirm the shapes of the datasets\n",
    "assert train_texts.shape[0] == y_train.shape[0], \"Mismatch in train data and labels\"\n",
    "assert val_texts.shape[0] == y_val.shape[0], \"Mismatch in train data and labels\"\n",
    "assert test_texts.shape[0] == y_test.shape[0], \"Mismatch in test data and labels\"\n",
    "\n",
    "train_texts, test_texts = train_texts.ravel(), test_texts.ravel()\n",
    "val_texts = val_texts.ravel()\n",
    "\n",
    "print(train_texts.shape, y_train.shape, val_texts.shape, test_texts.shape)\n",
    "train_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Save data to csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to DataFrame\n",
    "train_texts_df = pd.DataFrame(train_texts, columns=['text'])\n",
    "val_texts_df = pd.DataFrame(val_texts, columns=['text'])\n",
    "test_texts_df = pd.DataFrame(test_texts, columns=['text'])\n",
    "\n",
    "# Convert labels to DataFrame\n",
    "y_train_df = pd.DataFrame(y_train, columns=df_labels.columns)\n",
    "y_val_df = pd.DataFrame(y_val, columns=df_labels.columns)\n",
    "y_test_df = pd.DataFrame(y_test, columns=df_labels.columns)\n",
    "\n",
    "# Save texts and labels to separate CSV files\n",
    "train_texts_df.to_csv('../dataset/train_texts.csv', index=False, sep=';')\n",
    "val_texts_df.to_csv('../dataset/val_texts.csv', index=False, sep=';')\n",
    "test_texts_df.to_csv('../dataset/test_texts.csv', index=False, sep=';')\n",
    "\n",
    "y_train_df.to_csv('../dataset/y_train.csv', index=False, sep=';')\n",
    "y_val_df.to_csv('../dataset/y_val.csv', index=False, sep=';')\n",
    "y_test_df.to_csv('../dataset/y_test.csv', index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

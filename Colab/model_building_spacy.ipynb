{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "from sklearn.metrics import f1_score,  precision_score, recall_score, hamming_loss\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from keras.metrics import AUC\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "import spacy\n",
        "from spacy.training import Example\n",
        "from spacy.util import minibatch\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Load Cleaned Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3974, 1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>er is een teek op mijn been ik ben bang dat di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>er is een teek op mijn rug en ik krijg hem er ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>op mijn been zit een teek ik heb hem geprobeer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ik heb allergieen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>huid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>roodheid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>schilfering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ik heb wratten onder mijn voet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ik heb gisteren naar het bos geweest en zie nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ik voelde iets prikken</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  er is een teek op mijn been ik ben bang dat di...\n",
              "1  er is een teek op mijn rug en ik krijg hem er ...\n",
              "2  op mijn been zit een teek ik heb hem geprobeer...\n",
              "3                                  ik heb allergieen\n",
              "4                                               huid\n",
              "5                                           roodheid\n",
              "6                                        schilfering\n",
              "7                     ik heb wratten onder mijn voet\n",
              "8  ik heb gisteren naar het bos geweest en zie nu...\n",
              "9                             ik voelde iets prikken"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the cleaned datasets\n",
        "df_user_inputs = pd.read_csv('../dataset/user_inputs_cleaned.csv')\n",
        "df_labels = pd.read_csv('../dataset//labels_cleaned.csv')\n",
        "\n",
        "# Remove unnecessary index columns\n",
        "df_user_inputs.drop(df_user_inputs.columns[0], axis=1, inplace=True)\n",
        "df_labels.drop(df_labels.columns[0], axis=1, inplace=True)\n",
        "\n",
        "# Ensure alignment\n",
        "assert len(df_labels) == len(df_user_inputs), \"Datasets do not align!\"\n",
        "\n",
        "print(df_user_inputs.shape)\n",
        "df_user_inputs.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Niet lekker voelen, algehele malaise</th>\n",
              "      <th>Beenklachten</th>\n",
              "      <th>Bloedneus</th>\n",
              "      <th>Misselijkheid en overgeven</th>\n",
              "      <th>Brandwond</th>\n",
              "      <th>Buikpijn</th>\n",
              "      <th>Suikerziekte (ontregeld)</th>\n",
              "      <th>Diarree</th>\n",
              "      <th>Duizeligheid</th>\n",
              "      <th>Gebitsklachten</th>\n",
              "      <th>...</th>\n",
              "      <th>Coronavirus</th>\n",
              "      <th>Knieklachten</th>\n",
              "      <th>Liesklachten</th>\n",
              "      <th>Elleboogklachten</th>\n",
              "      <th>Schouderklachten</th>\n",
              "      <th>Oorsuizen</th>\n",
              "      <th>Hand- en polsklachten</th>\n",
              "      <th>Enkelklachten</th>\n",
              "      <th>Dikke enkels of voeten</th>\n",
              "      <th>Vingerklachten</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 74 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Niet lekker voelen, algehele malaise  Beenklachten  Bloedneus  \\\n",
              "0                                   0.0           0.0        0.0   \n",
              "1                                   0.0           0.0        0.0   \n",
              "2                                   0.0           0.0        0.0   \n",
              "3                                   0.0           0.0        0.0   \n",
              "4                                   0.0           0.0        0.0   \n",
              "\n",
              "   Misselijkheid en overgeven  Brandwond  Buikpijn  Suikerziekte (ontregeld)  \\\n",
              "0                         0.0        0.0       0.0                       0.0   \n",
              "1                         0.0        0.0       0.0                       0.0   \n",
              "2                         0.0        0.0       0.0                       0.0   \n",
              "3                         0.0        0.0       0.0                       0.0   \n",
              "4                         0.0        0.0       0.0                       0.0   \n",
              "\n",
              "   Diarree  Duizeligheid  Gebitsklachten  ...  Coronavirus  Knieklachten  \\\n",
              "0      0.0           0.0             0.0  ...          0.0           0.0   \n",
              "1      0.0           0.0             0.0  ...          0.0           0.0   \n",
              "2      0.0           0.0             0.0  ...          0.0           0.0   \n",
              "3      0.0           0.0             0.0  ...          0.0           0.0   \n",
              "4      0.0           0.0             0.0  ...          0.0           0.0   \n",
              "\n",
              "   Liesklachten  Elleboogklachten  Schouderklachten  Oorsuizen  \\\n",
              "0           0.0               0.0               0.0        0.0   \n",
              "1           0.0               0.0               0.0        0.0   \n",
              "2           0.0               0.0               0.0        0.0   \n",
              "3           0.0               0.0               0.0        0.0   \n",
              "4           0.0               0.0               0.0        0.0   \n",
              "\n",
              "   Hand- en polsklachten  Enkelklachten  Dikke enkels of voeten  \\\n",
              "0                    0.0            0.0                     0.0   \n",
              "1                    0.0            0.0                     0.0   \n",
              "2                    0.0            0.0                     0.0   \n",
              "3                    0.0            0.0                     0.0   \n",
              "4                    0.0            0.0                     0.0   \n",
              "\n",
              "   Vingerklachten  \n",
              "0             0.0  \n",
              "1             0.0  \n",
              "2             0.0  \n",
              "3             0.0  \n",
              "4             0.0  \n",
              "\n",
              "[5 rows x 74 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Huidklachten                            0.088827\n",
              "Beenklachten                            0.072723\n",
              "Buikpijn                                0.062154\n",
              "Oorklachten                             0.052843\n",
              "Misselijkheid en overgeven              0.037242\n",
              "                                          ...   \n",
              "Liesklachten                            0.005033\n",
              "Tekenbeet                               0.005033\n",
              "Verdrinking                             0.005033\n",
              "Verwonding aan de buik                  0.005033\n",
              "Niet lekker voelen, algehele malaise    0.002516\n",
              "Length: 74, dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Determine model baseline\n",
        "label_frequencies = df_labels.sum().sort_values(ascending=False)\n",
        "label_frequencies / df_labels.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that if we predict every time the label with the highest frequency (Huidklachten), our model will be correct around 9% of the time. We want our model to perform at least better than this 9% threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Prepare Data to Model Format**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To accomodate the nature of multi-label classification. Instead of using the traditional method `train_test_split`, we employ iterative stratified sampling `iterative_train_test_split`, to provide a well-balanced distribution of all label combinations in both training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3175,) (3175, 74) (799,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(['er is een teek op mijn been ik ben bang dat die er al een tijdje op heeft gezeten',\n",
              "       'op mijn been zit een teek ik heb hem geprobeerd te verwijderen maar het lukt niet',\n",
              "       'ik heb allergieen', ...,\n",
              "       'vannacht met slapen denk ik gekke beweging gemaakt want mn nek is nu helemaal stijf kan niet meer naar rechts kijken',\n",
              "       'heb al langere tijd pijn in mn nek krijg dan soms tintelingen over mijn arm heb dan ook minder kracht in mijn arm',\n",
              "       'doet zeer als ik mn hoofd beweeg'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Split data to train:val:test\n",
        "\n",
        "# Prepare data for iterative train test split\n",
        "# X must be 2D np.ndarray and y must be 2D binary np.ndarray\n",
        "X_texts = df_user_inputs['text'].values\n",
        "X_texts = X_texts.reshape(-1, 1)\n",
        "y = df_labels.values\n",
        "\n",
        "# Split the data 60:20:20 with multi-label stratification\n",
        "train_texts, y_train, test_texts, y_test = iterative_train_test_split(X_texts, y, test_size = 0.2)\n",
        "#val_texts, y_val, test_texts, y_test = iterative_train_test_split(tmp_texts, y_tmp, test_size = 0.5)\n",
        "\n",
        "# Sanity checks to confirm the shapes of the datasets\n",
        "assert train_texts.shape[0] == y_train.shape[0], \"Mismatch in train data and labels\"\n",
        "assert test_texts.shape[0] == y_test.shape[0], \"Mismatch in test data and labels\"\n",
        "\n",
        "train_texts, test_texts = train_texts.ravel(), test_texts.ravel()\n",
        "#val_texts = val_texts.ravel()\n",
        "\n",
        "print(train_texts.shape, y_train.shape, test_texts.shape)\n",
        "train_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Model Building: spaCy NL**\n",
        "\n",
        "For simplicity, we train and evaluate base classifiers with OneVsRestClassifier. We select classifiers that are known to work well with multi-label text classification, such as Naive Bayes, SVM, and Logistic Regression.\n",
        "\n",
        "To handle class imbalance, we consider the following:\n",
        "- Class weights in loss function\n",
        "- Evaluation metrics: F1 score (micro) for individual labels and Hamming loss for overall metrics (i.e. evaluate label prediction rather than label combination)\n",
        "\n",
        "We identify the best-performing classifier based on the F1 score and Hamming Loss. Then we proceed to test this classifer with more advanced techniques that consider label correlations, i.e. Classifier Chains (CC) and Random k-Labelsets (RAkEL)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **A. Data & Model Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_spacy_model(model_size=\"sm\"):\n",
        "  \"\"\"\n",
        "  Initialize and return a spaCy model with a text classification component.\n",
        "  Args:\n",
        "      model_size (str): Size of the spaCy Dutch language model.\n",
        "  Returns:\n",
        "      spacy.Language: An initialized spaCy model.\n",
        "  \"\"\"\n",
        "  nlp = spacy.load(f'nl_core_news_{model_size}')\n",
        "\n",
        "  \"\"\"\n",
        "  # If we have more time, we could add in transformer which could boost performance\n",
        "  # Configure the transformer\n",
        "  transformer_config = {\n",
        "      \"model\": {\n",
        "          \"@architectures\": \"spacy-transformers.TransformerModel.v1\",\n",
        "          \"name\": \"wietsedv/bert-base-dutch-cased\",\n",
        "          \"tokenizer_config\": {\"use_fast\": True},\n",
        "          \"get_spans\": {\"@span_getters\": \"spacy-transformers.strided_spans.v1\", \"window\": 128, \"stride\": 96}\n",
        "      }\n",
        "  }\n",
        "\n",
        "  # Add transformer to the pipeline\n",
        "  transformer = nlp.add_pipe(\"transformer\", config=transformer_config)\n",
        "  \"\"\"\n",
        "\n",
        "  # Add text classification component\n",
        "  textcat = nlp.add_pipe(\"textcat_multilabel\", last=True)\n",
        "\n",
        "  # Add labels to text classifier\n",
        "  for label in df_labels.columns:\n",
        "      textcat.add_label(label)\n",
        "\n",
        "  nlp.initialize()\n",
        "\n",
        "  return nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# training examples: 3175\n",
            "# test examples: 799\n"
          ]
        }
      ],
      "source": [
        "def prepare_spacy_data(set_texts, y_set, model_size=\"sm\"):\n",
        "  \"\"\"\n",
        "  Prepares the training/test data in the format required by spaCy for model training/evaluation.\n",
        "\n",
        "  Args:\n",
        "      set_texts (np.ndarray): Array of training/test texts\n",
        "      y_set (np.ndarray): Array of train/test labels\n",
        "      model_size (str): The size of the pre-trained spaCy Dutch language model to use. Set default to small.\n",
        "\n",
        "  Returns:\n",
        "      list: A list of spaCy Example objects representing the training/test data.\n",
        "  \"\"\"\n",
        "\n",
        "  nlp = initialize_spacy_model(model_size) # just for spacy data preparation\n",
        "\n",
        "  set_data = []\n",
        "  for text, labels in zip(set_texts, y_set):\n",
        "      doc = nlp.make_doc(text)\n",
        "      example = Example.from_dict(doc, {\"cats\": {label: labels[idx] for idx, label in enumerate(df_labels.columns)}})\n",
        "      set_data.append(example)\n",
        "\n",
        "  return set_data\n",
        "\n",
        "train_data = prepare_spacy_data(train_texts, y_train)\n",
        "print(f\"# training examples: {len(train_data)}\")\n",
        "\n",
        "test_data = prepare_spacy_data(test_texts, y_test)\n",
        "print(f\"# test examples: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# training examples after oversampling: 3907\n"
          ]
        }
      ],
      "source": [
        "def oversample_spacy(train_data, df_labels, threshold=30):\n",
        "    \"\"\"\n",
        "    Applies custom oversampling to the minority classes in the training data to address class imbalance.\n",
        "\n",
        "    Args:\n",
        "        train_data (list): The list of training data examples (spaCy Example objects).\n",
        "        df_labels (pd.DataFrame): The DataFrame containing the labels for each training example.\n",
        "        threshold (int): The threshold for identifying minority classes to be oversampled.\n",
        "\n",
        "    Returns:\n",
        "        list: The modified training data after applying oversampling.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert labels to a numpy array for processing\n",
        "    labels = np.array([list(example.y.cats.values()) for example in train_data])\n",
        "    # Identify minority classes\n",
        "    minority_labels = (labels.sum(axis=0) < threshold)\n",
        "    # Identify instances with minority class labels\n",
        "    minority_instances = labels[:, minority_labels].sum(axis=1) > 0\n",
        "    # Oversample these instances\n",
        "    oversampled_data = [train_data[i] for i, is_minority in enumerate(minority_instances) if is_minority]\n",
        "    # Combine with original data\n",
        "    combined_data = train_data + oversampled_data * 1\n",
        "\n",
        "    return combined_data\n",
        "\n",
        "train_data = oversample_spacy(train_data, df_labels)\n",
        "print(f\"# training examples after oversampling: {len(train_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **B. Set up Model Training & Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_spacy_model(model_size=\"sm\"):\n",
        "  \"\"\"\n",
        "  Train a spaCy model using k-fold cross-validation and return the trained model.\n",
        "  Args:\n",
        "      model_size (str): Size of the spaCy Dutch language model.\n",
        "  Returns:\n",
        "      spacy.Language: A trained spaCy model.\n",
        "  \"\"\"\n",
        "  N_EPOCHS = 50\n",
        "  BATCH_SIZE = 128\n",
        "  DROPOUT = 0.2\n",
        "\n",
        "  train_data = prepare_spacy_data(train_texts, y_train, model_size)\n",
        "\n",
        "  kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
        "  validation_scores = []\n",
        "  hamming_losses = []\n",
        "\n",
        "  print(\"Training the model...\")\n",
        "\n",
        "  # Cross-validation\n",
        "  for fold, (train_indices, val_indices) in enumerate(kf.split(train_data)):\n",
        "      print(f\"\\nFold {fold + 1}\")\n",
        "      print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format(\n",
        "            'EPOCH', 'TR_LOSS', 'TR_AUC', 'VAL_AUC', 'TR_F1', 'VAL_F1', 'TR_P', 'VAL_P', 'TR_R', 'VAL_R'))\n",
        "\n",
        "      nlp = initialize_spacy_model(model_size)  # Initialize a new model for each fold\n",
        "\n",
        "      train_fold = [train_data[i] for i in train_indices]\n",
        "      val_fold = [train_data[i] for i in val_indices]\n",
        "\n",
        "      for epoch in range(N_EPOCHS):\n",
        "          losses = {}\n",
        "          random.shuffle(train_fold)\n",
        "          for batch in minibatch(train_fold, size=BATCH_SIZE):\n",
        "              nlp.update(batch, drop=DROPOUT, losses=losses)\n",
        "\n",
        "          # Evaluate on train and validation set\n",
        "          train_scores = nlp.evaluate(train_fold)\n",
        "          val_scores = nlp.evaluate(val_fold)\n",
        "          print('{0:d}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\\t{4:.3f}\\t{5:.3f}\\t{6:.3f}\\t{7:.3f}\\t{8:.3f}\\t{9:.3f}'.format(\n",
        "                int(epoch), losses['textcat_multilabel'],\n",
        "                train_scores['cats_macro_auc'], val_scores['cats_macro_auc'],\n",
        "                train_scores['cats_micro_f'], val_scores['cats_micro_f'],\n",
        "                train_scores['cats_micro_p'], val_scores['cats_micro_p'],\n",
        "                train_scores['cats_micro_r'], val_scores['cats_micro_r']))\n",
        "\n",
        "\n",
        "      # Evaluate on validation fold\n",
        "      y_true = np.array([list(example.y.cats.values()) for example in val_fold])\n",
        "      y_pred = np.array([list(nlp(example.x.text).cats.values()) for example in val_fold])\n",
        "      y_pred_binary = (y_pred >= 0.5).astype(int)\n",
        "      hamming = hamming_loss(y_true, y_pred_binary)\n",
        "\n",
        "      hamming_losses.append(hamming)\n",
        "      validation_scores.append(val_scores)\n",
        "\n",
        "  return nlp, validation_scores, hamming_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Evaluate spacy model on validation data from training averaged across k-folds\n",
        "def spacy_val_hamming_loss(hamming_losses):\n",
        "  \"\"\"\n",
        "  Evaluates and prints the average F1 score and Hamming loss across validation folds.\n",
        "\n",
        "  Args:\n",
        "      hamming_losses (list): List of Hamming loss values from each validation fold.\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculate and print average metrics\n",
        "  average_hamming = np.mean(hamming_losses)\n",
        "  print(f\"Average Validation Hamming Loss: {average_hamming}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Evaluate spacy model on test data\n",
        "def spacy_test_hamming_loss(nlp, test_data):\n",
        "  \"\"\"\n",
        "  Evaluates the spaCy model on the test data and prints the F1 score and Hamming loss.\n",
        "\n",
        "  Args:\n",
        "      nlp (spacy.Language): The trained spaCy model.\n",
        "      test_data (list): A list of spaCy Example objects representing the test data.\n",
        "  \"\"\"\n",
        "\n",
        "  # Predict and evaluate\n",
        "  y_true_test = np.array([list(example.y.cats.values()) for example in test_data])\n",
        "  y_pred_test = np.array([list(nlp(example.x.text).cats.values()) for example in test_data])\n",
        "\n",
        "  # Binarize y_pred_test\n",
        "  y_pred_test_binary = (y_pred_test >= 0.5).astype(int)\n",
        "\n",
        "  # Calculate Hamming loss for the test set\n",
        "  hamming_test = hamming_loss(y_true_test, y_pred_test_binary)\n",
        "\n",
        "  print(f\"Test Hamming Loss: {hamming_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **C. Model Development and Experimentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_spacy_model(model_size=\"sm\"):\n",
        "  \"\"\"\n",
        "  Train a spaCy model using k-fold cross-validation and return the trained model.\n",
        "  Args:\n",
        "      model_size (str): Size of the spaCy Dutch language model.\n",
        "  Returns:\n",
        "      spacy.Language: A trained spaCy model.\n",
        "  \"\"\"\n",
        "  N_EPOCHS = 50\n",
        "  BATCH_SIZE = 128\n",
        "  DROPOUT = 0.2\n",
        "  KFOLD_SIZE = 5\n",
        "\n",
        "  train_data = prepare_spacy_data(train_texts, y_train, model_size)\n",
        "\n",
        "  kf = KFold(n_splits=KFOLD_SIZE, shuffle=True, random_state=42)\n",
        "  validation_scores = []\n",
        "  hamming_losses = []\n",
        "\n",
        "  print(\"Training the model...\")\n",
        "\n",
        "  # Cross-validation\n",
        "  for fold, (train_indices, val_indices) in enumerate(kf.split(train_data)):\n",
        "      print(f\"\\nFold {fold + 1}\")\n",
        "      print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format(\n",
        "            'EPOCH', 'TR_LOSS', 'TR_AUC', 'VAL_AUC', 'TR_F1', 'VAL_F1', 'TR_P', 'VAL_P', 'TR_R', 'VAL_R'))\n",
        "\n",
        "      nlp = initialize_spacy_model(model_size)  # Initialize a new model for each fold\n",
        "\n",
        "      train_fold = [train_data[i] for i in train_indices]\n",
        "      val_fold = [train_data[i] for i in val_indices]\n",
        "\n",
        "      for epoch in range(N_EPOCHS):\n",
        "          losses = {}\n",
        "          random.shuffle(train_fold)\n",
        "          for batch in minibatch(train_fold, size=BATCH_SIZE):\n",
        "              nlp.update(batch, drop=DROPOUT, losses=losses)\n",
        "\n",
        "          # Evaluate on train and validation set\n",
        "          train_scores = nlp.evaluate(train_fold)\n",
        "          val_scores = nlp.evaluate(val_fold)\n",
        "          print('{0:d}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\\t{4:.3f}\\t{5:.3f}\\t{6:.3f}\\t{7:.3f}\\t{8:.3f}\\t{9:.3f}'.format(\n",
        "                int(epoch), losses['textcat_multilabel'],\n",
        "                train_scores['cats_macro_auc'], val_scores['cats_macro_auc'],\n",
        "                train_scores['cats_micro_f'], val_scores['cats_micro_f'],\n",
        "                train_scores['cats_micro_p'], val_scores['cats_micro_p'],\n",
        "                train_scores['cats_micro_r'], val_scores['cats_micro_r']))\n",
        "\n",
        "\n",
        "      # Evaluate on validation fold\n",
        "      y_true = np.array([list(example.y.cats.values()) for example in val_fold])\n",
        "      y_pred = np.array([list(nlp(example.x.text).cats.values()) for example in val_fold])\n",
        "      y_pred_binary = (y_pred >= 0.5).astype(int)\n",
        "      hamming = hamming_loss(y_true, y_pred_binary)\n",
        "\n",
        "      hamming_losses.append(hamming)\n",
        "      validation_scores.append(val_scores)\n",
        "\n",
        "  return nlp, validation_scores, hamming_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Evaluate spacy model on validation data from training averaged across k-folds\n",
        "def evaluate_spacy_validation(f1_scores, hamming_losses):\n",
        "  \"\"\"\n",
        "  Evaluates and prints the average F1 score and Hamming loss across validation folds.\n",
        "\n",
        "  Args:\n",
        "      f1_scores (list): List of F1 scores from each validation fold.\n",
        "      hamming_losses (list): List of Hamming loss values from each validation fold.\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculate and print average metrics\n",
        "  average_f1 = np.mean(f1_scores)\n",
        "  average_hamming = np.mean(hamming_losses)\n",
        "  print(f\"Average Validation F1 Score: {average_f1}\")\n",
        "  print(f\"Average Validation Hamming Loss: {average_hamming}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Evaluate spacy model on test data\n",
        "def evaluate_spacy_test(nlp, test_data):\n",
        "  \"\"\"\n",
        "  Evaluates the spaCy model on the test data and prints the F1 score and Hamming loss.\n",
        "\n",
        "  Args:\n",
        "      nlp (spacy.Language): The trained spaCy model.\n",
        "      test_data (list): A list of spaCy Example objects representing the test data.\n",
        "  \"\"\"\n",
        "\n",
        "  # Predict and evaluate\n",
        "  y_true_test = np.array([list(example.y.cats.values()) for example in test_data])\n",
        "  y_pred_test = np.array([list(nlp(example.x.text).cats.values()) for example in test_data])\n",
        "\n",
        "  # Binarize y_pred_test\n",
        "  y_pred_test_binary = (y_pred_test >= 0.5).astype(int)\n",
        "\n",
        "  # Calculate F1 score and Hamming loss for the test set\n",
        "  f1_test = f1_score(y_true_test, y_pred_test_binary, average='micro')\n",
        "  hamming_test = hamming_loss(y_true_test, y_pred_test_binary)\n",
        "\n",
        "  print(f\"Test F1 Score: {f1_test}\")\n",
        "  print(f\"Test Hamming Loss: {hamming_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **D. Train spaCy model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEGslD7Dj-Nt",
        "outputId": "4830bd9e-c2b3-4eac-dacf-fd5ef955c17b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training the model...\n",
            "\n",
            "Fold 1\n",
            "EPOCH\tTR_LOSS\tTR_AUC\tVAL_AUC\tTR_F1\tVAL_F1\tTR_P \tVAL_P\tTR_R \tVAL_R\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/pipeline/attributeruler.py:149: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
            "  matches = self.matcher(doc, allow_missing=True, as_spans=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\t2.384\t0.526\t0.521\t0.010\t0.013\t0.007\t0.009\t0.018\t0.022\n",
            "1\t0.388\t0.565\t0.541\t0.000\t0.000\t0.000\t0.000\t0.000\t0.000\n",
            "2\t0.211\t0.617\t0.571\t0.000\t0.000\t0.000\t0.000\t0.000\t0.000\n",
            "3\t0.208\t0.647\t0.596\t0.000\t0.000\t0.000\t0.000\t0.000\t0.000\n",
            "4\t0.203\t0.655\t0.607\t0.022\t0.013\t0.955\t0.812\t0.011\t0.007\n",
            "5\t0.197\t0.660\t0.617\t0.163\t0.083\t0.892\t0.733\t0.090\t0.044\n",
            "6\t0.188\t0.664\t0.627\t0.246\t0.127\t0.865\t0.677\t0.143\t0.070\n",
            "7\t0.181\t0.670\t0.636\t0.322\t0.179\t0.886\t0.723\t0.197\t0.102\n",
            "8\t0.174\t0.676\t0.645\t0.367\t0.199\t0.899\t0.736\t0.230\t0.115\n",
            "9\t0.165\t0.684\t0.653\t0.419\t0.229\t0.927\t0.712\t0.271\t0.137\n",
            "10\t0.159\t0.689\t0.661\t0.468\t0.257\t0.932\t0.709\t0.313\t0.157\n",
            "11\t0.151\t0.697\t0.668\t0.502\t0.270\t0.938\t0.726\t0.342\t0.166\n",
            "12\t0.143\t0.699\t0.670\t0.557\t0.310\t0.932\t0.703\t0.397\t0.199\n",
            "13\t0.139\t0.704\t0.676\t0.587\t0.321\t0.954\t0.729\t0.424\t0.206\n",
            "14\t0.133\t0.711\t0.683\t0.621\t0.349\t0.952\t0.716\t0.461\t0.231\n",
            "15\t0.128\t0.714\t0.687\t0.635\t0.360\t0.942\t0.692\t0.479\t0.243\n",
            "16\t0.122\t0.714\t0.687\t0.665\t0.366\t0.963\t0.726\t0.508\t0.245\n",
            "17\t0.120\t0.721\t0.691\t0.677\t0.375\t0.962\t0.702\t0.522\t0.256\n",
            "18\t0.116\t0.724\t0.693\t0.697\t0.383\t0.965\t0.702\t0.546\t0.263\n",
            "19\t0.112\t0.731\t0.699\t0.713\t0.399\t0.958\t0.693\t0.568\t0.280\n",
            "20\t0.107\t0.738\t0.700\t0.727\t0.391\t0.970\t0.705\t0.581\t0.271\n",
            "21\t0.104\t0.741\t0.702\t0.744\t0.407\t0.972\t0.690\t0.602\t0.289\n",
            "22\t0.101\t0.746\t0.707\t0.756\t0.405\t0.967\t0.695\t0.620\t0.285\n",
            "23\t0.096\t0.752\t0.712\t0.768\t0.407\t0.974\t0.677\t0.633\t0.291\n",
            "24\t0.093\t0.754\t0.714\t0.776\t0.417\t0.978\t0.687\t0.643\t0.300\n",
            "25\t0.091\t0.758\t0.716\t0.784\t0.418\t0.978\t0.688\t0.655\t0.300\n",
            "26\t0.088\t0.760\t0.717\t0.797\t0.430\t0.974\t0.680\t0.674\t0.314\n",
            "27\t0.086\t0.765\t0.714\t0.802\t0.425\t0.981\t0.674\t0.678\t0.311\n",
            "28\t0.082\t0.769\t0.720\t0.807\t0.424\t0.977\t0.690\t0.687\t0.307\n",
            "29\t0.082\t0.773\t0.723\t0.817\t0.431\t0.982\t0.676\t0.699\t0.316\n",
            "30\t0.078\t0.777\t0.728\t0.825\t0.434\t0.985\t0.674\t0.710\t0.320\n",
            "31\t0.077\t0.779\t0.731\t0.828\t0.417\t0.988\t0.672\t0.713\t0.302\n",
            "32\t0.075\t0.784\t0.734\t0.835\t0.427\t0.985\t0.654\t0.725\t0.317\n",
            "33\t0.073\t0.786\t0.736\t0.839\t0.430\t0.987\t0.666\t0.729\t0.318\n",
            "34\t0.071\t0.788\t0.738\t0.844\t0.437\t0.985\t0.672\t0.739\t0.324\n",
            "35\t0.068\t0.790\t0.740\t0.852\t0.442\t0.982\t0.655\t0.753\t0.334\n",
            "36\t0.069\t0.793\t0.742\t0.855\t0.437\t0.988\t0.661\t0.754\t0.327\n",
            "37\t0.066\t0.799\t0.747\t0.860\t0.441\t0.987\t0.662\t0.762\t0.331\n",
            "38\t0.065\t0.803\t0.751\t0.863\t0.442\t0.985\t0.662\t0.768\t0.332\n",
            "39\t0.062\t0.809\t0.755\t0.867\t0.441\t0.986\t0.663\t0.774\t0.331\n",
            "40\t0.061\t0.815\t0.756\t0.871\t0.454\t0.984\t0.659\t0.782\t0.346\n",
            "41\t0.058\t0.820\t0.758\t0.876\t0.461\t0.985\t0.663\t0.788\t0.353\n",
            "42\t0.057\t0.822\t0.760\t0.880\t0.453\t0.989\t0.662\t0.792\t0.344\n",
            "43\t0.057\t0.825\t0.762\t0.882\t0.450\t0.990\t0.645\t0.795\t0.345\n",
            "44\t0.055\t0.825\t0.763\t0.885\t0.451\t0.987\t0.660\t0.802\t0.343\n",
            "45\t0.054\t0.828\t0.767\t0.890\t0.464\t0.984\t0.650\t0.812\t0.361\n",
            "46\t0.053\t0.829\t0.767\t0.893\t0.464\t0.984\t0.660\t0.818\t0.358\n",
            "47\t0.050\t0.831\t0.766\t0.896\t0.462\t0.985\t0.648\t0.822\t0.359\n",
            "48\t0.048\t0.833\t0.769\t0.900\t0.461\t0.983\t0.657\t0.829\t0.354\n",
            "49\t0.047\t0.836\t0.770\t0.902\t0.457\t0.983\t0.660\t0.834\t0.349\n",
            "\n",
            "Fold 2\n",
            "EPOCH\tTR_LOSS\tTR_AUC\tVAL_AUC\tTR_F1\tVAL_F1\tTR_P \tVAL_P\tTR_R \tVAL_R\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/pipeline/attributeruler.py:149: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
            "  matches = self.matcher(doc, allow_missing=True, as_spans=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\t2.373\t0.522\t0.503\t0.026\t0.016\t0.026\t0.015\t0.027\t0.018\n",
            "1\t0.375\t0.548\t0.527\t0.000\t0.000\t0.000\t0.000\t0.000\t0.000\n",
            "2\t0.212\t0.609\t0.557\t0.000\t0.000\t0.000\t0.000\t0.000\t0.000\n",
            "3\t0.208\t0.646\t0.582\t0.000\t0.000\t0.000\t0.000\t0.000\t0.000\n",
            "4\t0.205\t0.664\t0.600\t0.029\t0.015\t0.879\t0.750\t0.015\t0.008\n",
            "5\t0.198\t0.666\t0.601\t0.108\t0.049\t0.874\t0.620\t0.057\t0.025\n",
            "6\t0.188\t0.664\t0.602\t0.205\t0.132\t0.859\t0.695\t0.116\t0.073\n",
            "7\t0.181\t0.665\t0.608\t0.284\t0.179\t0.886\t0.727\t0.169\t0.102\n",
            "8\t0.171\t0.666\t0.619\t0.422\t0.262\t0.883\t0.672\t0.277\t0.163\n",
            "9\t0.161\t0.673\t0.631\t0.483\t0.297\t0.897\t0.694\t0.331\t0.189\n",
            "10\t0.153\t0.681\t0.637\t0.529\t0.320\t0.917\t0.712\t0.372\t0.206\n",
            "11\t0.146\t0.683\t0.644\t0.572\t0.350\t0.919\t0.700\t0.415\t0.233\n",
            "12\t0.140\t0.688\t0.649\t0.597\t0.355\t0.932\t0.706\t0.439\t0.238\n",
            "13\t0.133\t0.694\t0.656\t0.622\t0.369\t0.934\t0.689\t0.466\t0.252\n",
            "14\t0.129\t0.698\t0.660\t0.644\t0.363\t0.949\t0.676\t0.487\t0.248\n",
            "15\t0.123\t0.701\t0.666\t0.664\t0.370\t0.955\t0.679\t0.509\t0.255\n",
            "16\t0.119\t0.704\t0.669\t0.688\t0.388\t0.955\t0.669\t0.538\t0.273\n",
            "17\t0.116\t0.709\t0.672\t0.707\t0.387\t0.956\t0.670\t0.560\t0.272\n",
            "18\t0.111\t0.714\t0.676\t0.713\t0.392\t0.962\t0.674\t0.567\t0.276\n",
            "19\t0.109\t0.714\t0.678\t0.733\t0.408\t0.960\t0.674\t0.593\t0.293\n",
            "20\t0.104\t0.718\t0.680\t0.744\t0.396\t0.973\t0.691\t0.602\t0.277\n",
            "21\t0.101\t0.723\t0.684\t0.754\t0.412\t0.965\t0.676\t0.619\t0.297\n",
            "22\t0.099\t0.729\t0.689\t0.762\t0.412\t0.969\t0.659\t0.628\t0.299\n",
            "23\t0.096\t0.731\t0.687\t0.770\t0.415\t0.979\t0.692\t0.635\t0.296\n",
            "24\t0.092\t0.733\t0.689\t0.781\t0.425\t0.976\t0.666\t0.651\t0.312\n",
            "25\t0.090\t0.733\t0.687\t0.788\t0.423\t0.974\t0.664\t0.661\t0.310\n",
            "26\t0.087\t0.736\t0.689\t0.797\t0.429\t0.978\t0.664\t0.673\t0.317\n",
            "27\t0.085\t0.742\t0.694\t0.807\t0.423\t0.979\t0.662\t0.686\t0.311\n",
            "28\t0.079\t0.750\t0.702\t0.815\t0.427\t0.976\t0.672\t0.700\t0.313\n",
            "29\t0.079\t0.753\t0.704\t0.826\t0.435\t0.981\t0.675\t0.714\t0.321\n",
            "30\t0.077\t0.757\t0.709\t0.834\t0.436\t0.982\t0.670\t0.725\t0.324\n",
            "31\t0.073\t0.760\t0.715\t0.839\t0.442\t0.979\t0.658\t0.734\t0.333\n",
            "32\t0.072\t0.761\t0.718\t0.844\t0.442\t0.982\t0.678\t0.740\t0.328\n",
            "33\t0.071\t0.763\t0.718\t0.848\t0.435\t0.982\t0.671\t0.746\t0.322\n",
            "34\t0.067\t0.765\t0.719\t0.856\t0.440\t0.984\t0.666\t0.757\t0.328\n",
            "35\t0.066\t0.767\t0.719\t0.859\t0.443\t0.985\t0.653\t0.762\t0.336\n",
            "36\t0.065\t0.769\t0.720\t0.864\t0.438\t0.982\t0.650\t0.771\t0.330\n",
            "37\t0.063\t0.775\t0.722\t0.867\t0.438\t0.988\t0.662\t0.772\t0.327\n",
            "38\t0.063\t0.780\t0.723\t0.871\t0.452\t0.984\t0.652\t0.781\t0.345\n",
            "39\t0.058\t0.780\t0.723\t0.877\t0.434\t0.990\t0.666\t0.787\t0.322\n",
            "40\t0.060\t0.784\t0.724\t0.878\t0.450\t0.986\t0.643\t0.791\t0.346\n",
            "41\t0.057\t0.787\t0.728\t0.881\t0.447\t0.987\t0.645\t0.795\t0.342\n",
            "42\t0.057\t0.792\t0.735\t0.884\t0.448\t0.989\t0.651\t0.799\t0.341\n",
            "43\t0.056\t0.799\t0.741\t0.886\t0.442\t0.989\t0.647\t0.803\t0.336\n",
            "44\t0.053\t0.804\t0.744\t0.888\t0.454\t0.989\t0.645\t0.806\t0.351\n",
            "45\t0.052\t0.808\t0.746\t0.893\t0.444\t0.992\t0.656\t0.813\t0.336\n",
            "46\t0.051\t0.813\t0.749\t0.895\t0.440\t0.992\t0.661\t0.815\t0.329\n",
            "47\t0.049\t0.818\t0.752\t0.899\t0.444\t0.991\t0.626\t0.822\t0.344\n",
            "48\t0.049\t0.817\t0.753\t0.900\t0.444\t0.992\t0.641\t0.824\t0.340\n",
            "49\t0.049\t0.820\t0.754\t0.902\t0.450\t0.993\t0.638\t0.827\t0.348\n"
          ]
        }
      ],
      "source": [
        "nlp, f1_scores, hamming_losses = train_spacy_model(model_size=\"md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfr5IoDgrI62",
        "outputId": "d3c98570-1515-4977-d1a0-73bf6d1afce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Validation Hamming Loss: 0.013824256825285333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/pipeline/attributeruler.py:149: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
            "  matches = self.matcher(doc, allow_missing=True, as_spans=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Hamming Loss: 0.013564252613063627\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.7637546840199227,\n",
              " 0.4430555555555556,\n",
              " 0.6744186046511628,\n",
              " 0.3298862461220269)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spacy_val_hamming_loss(hamming_losses)\n",
        "\n",
        "# Evaluation metrics for test set\n",
        "test_data = prepare_spacy_data(test_texts, y_test, \"md\")\n",
        "test_scores = nlp.evaluate(test_data)\n",
        "spacy_test_hamming_loss(nlp, test_data)\n",
        "test_scores['cats_macro_auc'], test_scores['cats_micro_f'], test_scores['cats_micro_p'], test_scores['cats_micro_r']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YvF5pV9i28x"
      },
      "source": [
        "The low validation and test F1 scores suggest that the model's performance in classifying the multi-label data is not that great. The fact that both validation and test scores are similar indicates that the model is not overfitting. However, the low F1 scores could point to underfitting or a model that struggles to capture the complexities of the data.\n",
        "\n",
        "The Hamming loss being around 0.014 for both validation and test suggests a low rate of incorrect label assignments, which is good, but the F1 score implies there's room for improvement in the model's precision and recall balance.\n",
        "\n",
        "Suggested next steps for future:\n",
        "1. Implement Transformer-based Models: Try models like BERT or LLM (e.g. GPT, Llama2, Bloom, Mistral, etc) for better contextual understanding.\n",
        "2. Hyperparameter Tuning: Adjust learning rates, epochs, and batch sizes to optimize performance.\n",
        "3. Data Augmentation: Enhance the dataset, focusing on minority classes to address imbalance.\n",
        "4. Advanced Preprocessing: Refine text preprocessing to improve feature extraction.\n",
        "5. Error Analysis: Identify specific weaknesses of the model and target improvements accordingly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sro4tOWY5yJe"
      },
      "source": [
        "### **2.2.4. Serial Best SpaCy NL Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP3EJVbsPRDH",
        "outputId": "8379eb66-bb61-4115-baac-8555bdf6be80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/drive/MyDrive/Colab Notebooks/complaint_prediction_spacy\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model to a local directory in Google Colab\n",
        "output_directory = '../models/model_spacy'  # Replace with your desired output directory\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_directory):\n",
        "    os.makedirs(output_directory)\n",
        "\n",
        "# Save the trained model to the output directory\n",
        "nlp.to_disk(output_directory)\n",
        "\n",
        "# Verify that the model has been saved\n",
        "print(f\"Model saved to {output_directory}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Gc2PtDM5287v",
        "-iPltEt4bNUk",
        "-4w47NZyUtQZ",
        "ouSyNiHEXgm1",
        "1svoEzRszwZo",
        "m-1J9wF70GTt",
        "bDh422WI0LQA",
        "lq7tKtx039qi",
        "EuUqGq3a4Gs9",
        "9sJVGn_l364P",
        "DvuIOekWYL1x"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
